üèóÔ∏è The Smart Pavement Predictor: CBR Estimation ProjectThis project is all about using AI (Machine Learning) to make the critical job of pavement design faster, cheaper, and smarter.
The Big Problem We're SolvingBuilding roads, runways, and other paved areas requires knowing the strength of the soil underneath. 
The gold standard measurement is the California Bearing Ratio (CBR).Traditional Method: CBR requires digging up soil samples, bringing them to a lab, and running a specialized, often slow and expensive test. This process can be tedious and prone to delays.Our Solution: We create a "smart formula" that predicts the CBR based on data we already collect in the field‚Äîlike Plasticity Index (PI) and SPT blow counts ($N_{60}$)‚Äîplus the depth of the soil.This means we can get immediate, reliable CBR estimates right on site, saving time and money.üß† How the "Smart Formula" WorksInstead of using a simple, fixed linear equation, we use a sophisticated Machine Learning technique called Random Forest Regression.ShutterstockThink of it like this:Input Features (The Ingredients): We feed the model three easy-to-get pieces of information:$N_{60}$ (SPT Blow Count): How hard the ground is. (A measure of soil density/strength.)PI (Plasticity Index): How "clayey" or "sticky" the soil is. (A measure of soil type.)Depth: How far below the surface the sample was taken. (Soil strength often increases with depth.)The Model (The Chef): The Random Forest takes thousands of past examples where we knew all three inputs and the final measured CBR. It builds a complex "decision tree forest" to figure out the exact, non-linear relationship between them.The Output (The Prediction): We give the chef new ingredients (new PI, new $N_{60}$, new Depth), and it instantly spits out the predicted CBR value.üõ†Ô∏è In Simple Code StepsOur Python code follows a clear, four-step process:Gather & Prepare the Data: We load our spreadsheet of past projects, making sure all the PI and $N_{60}$ values are cleaned up and ready.Train the Model: We run the Random Forest algorithm on 80% of our historical data. This is where the model "learns" the patterns.Check the Answers: We test the model on the remaining 20% of data it has never seen. We measure how close its predictions are to the actual, measured CBR values using metrics like RMSE (Root Mean Square Error, smaller is better) and $R^2$ score (R-squared, closer to 1.0 is perfect).Predict the Future: We use the finalized model to predict the CBR for any new site where we only have PI, $N_{60}$, and Depth measurements.üöÄ What the Results MeanWhen you run the script, look at the $R^2$ Score:$R^2 = 0.95$: Fantastic! It means 95% of the variation in the CBR can be explained by our three input features. The model is highly reliable.$R^2 = 0.50$: Not so good. It means only 50% of the variation is captured, and the model needs better data or a 
different approach.
The visual scatter plot (Actual CBR vs. Predicted CBR) shows how good the model is. If the dots line up perfectly on the diagonal red line, the model is perfect.
